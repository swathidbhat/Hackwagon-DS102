{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i2.wp.com/hackwagon.com/wp-content/uploads/2017/02/Logo-Web-Export.png?ssl=1\" width=200/>\n",
    "\n",
    "<h1>Hackwagon Academy DS102 - Problem Set 1</h1>\n",
    "<hr>\n",
    "\n",
    "This Problem Set consists of 20 questions, with each correct answer to be awarded 1 mark, totalling up to 20 marks.\n",
    "\n",
    "If you have any questions to the Problem Set, feel free to send a message to your TAs or Instructors in the Telegram chat. You are encouraged to also discuss the problem sets within your own groups. \n",
    "\n",
    "Before you seek help, please consider looking at onlines resources such as documentations and try out those solutions first. This will greatly enhance your learning experience. Being stuck is part of the learning experience so don't worry!\n",
    "\n",
    "<b>Attempt but minor syntax errors are awarded half the mark.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before you start, please perform the following 2 steps:\n",
    "#1. Rename the file to FirstName_LastName Hackwagon Academy DS102 - Problem Set 1 \n",
    "#   e.g. John_Doe Hackwagon Academy DS102 - Problem Set 1\n",
    "\n",
    "#2. Fill in your details here:\n",
    "#Name                    : _______________________\n",
    "\n",
    "#Start of Course Class(Edit accordingly): __7 Jul 2019 3.15pm____\n",
    "\n",
    "# FOR TA/INSTRUCTOR \n",
    "# Total Marks:  / 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits \n",
    "\n",
    "This problem set is inspired by the [Lending Club Loan Data](https://www.kaggle.com/wendykan/lending-club-loan-data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://d1ic4altzx8ueg.cloudfront.net/niche-builder/5cb94cef96518.png\" width=300>\n",
    "\n",
    "## Context \n",
    "\n",
    "Congratulations! You've just joined LendingClub as their Data Analyst. LendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. \n",
    "\n",
    "Your project manager, Silver, knows you had just taken an intensive course on Data Analytics with Python has tasked your first Data Science project.  The project given to you is to help LendingClub prepare a prediction model to help them detect loan defaulters. As with all Data Science projects, Data Preprocessing is a crucial stage in any Data Science project, as such, this will be your very first task. \n",
    "\n",
    "The dataset handed to you are loans issued through 2007 - 2015 period including loan status. A data dictionary (`LCDataDictionary`) is also provided for you to get a better understanding of the dataset. \n",
    "\n",
    "Note: This problem set only tackles the <b>Data Gathering and Preprocessing</b> stage of the Data Science project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling & Preprocessing - 15 marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Open Files and Combine Datasets\n",
    "\n",
    "You're given two datasets:\n",
    "\n",
    "1. `loans-10k-1.csv`\n",
    "2. `loans-10k-2.csv`\n",
    "\n",
    "Combine these two datasets into a single dataframe as `df_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Inspect DataFrame\n",
    "\n",
    "Inspect the new DataFrame and know how many columns/variables you're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# How many rows and variables/columns are there in this dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Upon inspection, you noticed there are several missing values, like `NaN`, Not A Number, within the dataset. This pattern repeats for several columns. You have decided to inspect these columns further by investigating each column for the number of rows with missing values. You decide that you will drop columns where the number of rows with missing values are above a certain threshold, for this case would be 90%.  \n",
    "\n",
    "### Q3. Find Missing Data Per Column\n",
    "\n",
    "Using `.isnull()`, get the number of rows with missing data for each column using `.sum()` and store this Series as `missing_counts`. \n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "    id                 20000\n",
    "    member_id          20000\n",
    "    loan_amnt              0\n",
    "    funded_amnt            0\n",
    "    funded_amnt_inv        0\n",
    "    dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Get Missing Rows Information For Each Column\n",
    "\n",
    "Create a new Series called `missing_percentage` where it is the `missing_counts` divided by the number of rows, `len(df)`. With the two Series created, create a new DataFrame called, `missing_info_df`. \n",
    "\n",
    "After creating this new DataFrame, <b>filter</b> only for rows with at least 1 missing value and <b>display it</b>. \n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/gDQkDey.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: / 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Drop Insignificant Columns\n",
    "\n",
    "You've decided that there are many columns that have more than 90% missing values. You decide to drop these columns with the `.dropna` method, set to a threshold to 90% of the <b>total number of rows</b>. Set the new filtered DataFrame as `loans_significant_df`. \n",
    "\n",
    "<i>Hint: Check the <code>thresh</code> argument and set it <b>integer</b> value</i>\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/T1mNDfG.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Select Relevant Columns for Analysis \n",
    "\n",
    "The project manager of this project suggested looking into the following variables/columns for analysis, believing that they could be important in determining loan status: \n",
    "\n",
    "1. `loan_amnt`\n",
    "2. `term` \n",
    "3. `int_rate`\n",
    "4. `installment`\n",
    "5. `grade`\n",
    "6. `emp_length`\n",
    "7. `home_ownership`\n",
    "8. `annual_inc`\n",
    "9. `verification_status`\n",
    "10. `purpose`\n",
    "11. `dti`\n",
    "12. `delinq_2yrs`\n",
    "13. `loan_status`\n",
    "\n",
    "As such, filter down the previous DataFrame to just these columns, reducing from 86 columns to 14 columns. Name this new DataFrame as `loans_relevant_df`.  \n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/M99UOZE.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer Encoding \n",
    "\n",
    "Most machine learning models handle numeric data better. Within the current dataset, you observe that there are categorical variables. There are two ways to transform non-numeric data to numeric data: <b>One-Hot Encoding</b> and <b>Integer Encoding</b>. For scalability (lesser columns), you've decided to conduct <b>integer encoding</b> to transform non-numerical data to numerical data, (0 to n).\n",
    "\n",
    "The columns/variables to Integer Encode are:\n",
    "\n",
    "1. `term`\n",
    "2. `grade`\n",
    "3. `emp_length`\n",
    "4. `home_ownership`\n",
    "5. `verification_status`\n",
    "6.  `purpose`\n",
    "\n",
    "The `loan_status` is omitted for now as it is your target variable. \n",
    "\n",
    "There are a total of 3 cells for each of the next 7 questions:\n",
    "\n",
    "- Cell 1 - Inspect unique values\n",
    "- Cell 2 - Create function\n",
    "- Cell 3 - Apply function\n",
    "\n",
    "### Q7. Create Integer Encoded Column For `term`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection \n",
    "\n",
    "Inspect the `term` column and create transform the unique values to integers.\n",
    "\n",
    "There should be a total of <b>2</b> unique values: \n",
    "\n",
    "1. ' 36 months'\n",
    "2. ' 60 months'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function or Map\n",
    "\n",
    "With each unique value, encode them to integers between <b>0 to 1 </b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_encode_term():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply \n",
    "\n",
    "Using the above function, `apply` it to the `term` column and create a new column called `term_int` to `loans_relevant_df`.\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/6u3kb7k.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Create Integer Encoded Column For `grade`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection \n",
    "\n",
    "Inspect the `grade` column and create transform the unique values to integers.\n",
    "\n",
    "There should be a total of <b>7</b> unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function or Map\n",
    "\n",
    "With each unique value, encode them to integers between <b>0 to 6 (inclusive)</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply \n",
    "\n",
    "Using the above function, `apply` it to the `grade` column and create a new column called `grade_int` to `loans_relevant_df`.\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/yM0aZgN.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Create Integer Encoded Column For `emp_length`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection \n",
    "\n",
    "Inspect the `emp_length` column and create transform the unique values to integers.\n",
    "\n",
    "There should be a total of <b>12</b> unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function or Map\n",
    "\n",
    "With each unique value, encode them to integers between <b>-1 to 10 (inclusive)</b>, where -1 is for <b><code>NaN</code></b> values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply \n",
    "\n",
    "Using the above function, `apply` it to the `emp_length` column and create a new column called `emp_length_int` to `loans_relevant_df`.\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/sGzH2xg.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Create Integer Encoded Column For `home_ownership`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection \n",
    "\n",
    "Inspect the `home_ownership` column and create transform the unique values to integers.\n",
    "\n",
    "There should be a total of <b>6</b> unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function\n",
    "\n",
    "With each unique value, encode them to integers between <b>0 to 5(inclusive)</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply \n",
    "\n",
    "Using the above function, `apply` it to the `home_ownership` column and create a new column called `home_ownership_int` to `loans_relevant_df`.\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/53IOzA3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11. Create Integer Encoded Column For `verification_status` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection \n",
    "\n",
    "Inspect the `verification_status` column and create transform the unique values to integers.\n",
    "\n",
    "There should be a total of <b>3</b> unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function or Map\n",
    "\n",
    "With each unique value, encode them to integers between <b>0 to 2 (inclusive)</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply \n",
    "\n",
    "Using the above function, `apply` it to the `verification_status` column and create a new column called `verification_status_int` to `loans_relevant_df`.\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/BPhTJ3M.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12. Create Integer Encoded Column For `purpose`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection \n",
    "\n",
    "Inspect the `purpose` column and create transform the unique values to integers.\n",
    "\n",
    "There should be a total of <b>14</b> unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function or Map\n",
    "\n",
    "With each unique value, encode them to integers between <b>0 to 13 (inclusive)</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply \n",
    "\n",
    "Using the above function, `apply` it to the `purpose` column and create a new column called `purpose_int` to `loans_relevant_df`.\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/89aRMEl.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13. Create New `income_tax` column\n",
    "\n",
    "An **income tax** is imposed on the annual income of all registerants. The tax is calculated as follows:\n",
    "\n",
    "- if the annual income is $\\$65,000$ or less, the registrant does not need to pay tax\n",
    "- if the  annual income is more than $\\$65,000$ the registrant needs to pay a tax equal to $7.5\\%$ of his/her annual income\n",
    "\n",
    "Mathematically, for an registrant with an income of $\\$annual\\_income$, the amount of tax the registrant needs to pay, or the $\\$tax$ is:\n",
    "\n",
    "$$\n",
    "tax = \\begin{cases}\n",
    "0 & \\text{ if } annual\\_income \\leq 65000\\\\\n",
    "0.075 \\times annual\\_income & \\text{ if } annual\\_income > 65000\\\\\\end{cases}\n",
    "$$\n",
    "\n",
    "You've been tasked to create a new column called `income_tax` based on the above conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_income_tax():\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<img src=\"https://i.imgur.com/u54cP8a.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14. Save Transformed Data as CSV\n",
    "\n",
    "Save the transformed dataset, with both the numeric (integer encoded) and non-numerical data as a new CSV file as `loans_transformed.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q15. Save Numeric Only Data as CSV\n",
    "Save the transformed dataset with only the numeric variables as a new CSV file as `loans_transformed_numeric.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory & Statistical Analysis - 5 marks\n",
    "\n",
    "After performing data wrangling and preprocessing on the given datasets, you are now tasked to perform some descriptive analysis based on your processed dataset in order to better understand the dataset you're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16. Summary Statistics for Loan Amount for each Grade\n",
    "\n",
    "You're interested in finding out what is the distribution of the loan amounts issued by each grade. `groupby` the `loans_relevant_df` by its `grade` and `describe()` based on the `loan_amnt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17. Summary Statistics for Purpose for each Grade\n",
    "\n",
    "ou're interested in finding out what is the distribution of the loan amounts issued by each grade. `groupby` the `loans_relevant_df` by its `grade` and `describe()` based on the `purpose`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18.  `Charged Off` Proportion\n",
    "\n",
    "In order to better understand the scale of the default by grade, you decide to get the proportion of loans that are charged off based on each grade. This would allow you to narrow to a grade which could be an issue. \n",
    "\n",
    "`groupby` the `grade` and get the `size` of each grade and store it in a variable. On a separate second variable, filter the column `loan_status` for only `Charged Off` and then `groupby` `grade` from the filtered data and get the `size` of each grade. With these two variables, get the percentage by having the first variable divided by the second variable.\n",
    "\n",
    "<i>Note: Charged Off is the same as defaulting on a loan</i>\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "    grade\n",
    "    A    0.035526\n",
    "    B    0.078644\n",
    "    C    0.129395\n",
    "    D    0.193382\n",
    "    E    0.284553\n",
    "    F    0.308943\n",
    "    G    0.357143\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q19. Grade G Analysis -  Debt Consolidation\n",
    "\n",
    "Based on the earlier analysis, you've seen that Grade `G` has the highest proportion of defaulters. As such you decided to investigate further by looking at the proportion of debt consolidation for Grade `G`. \n",
    "\n",
    "Create 3 filter conditions:\n",
    "\n",
    "1. `loan_status` is `Charged Off`\n",
    "2. `grade` is `G`\n",
    "3. `purpose` is `debt_consolidation`\n",
    "\n",
    "Create two Grade `G` DataFrame of `debt_consolidation`, where one has `charged_off`, one does not then get the proportion of charged off over the total. \n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "    0.4027777777777778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q20. Outlier Analysis\n",
    "\n",
    "Your project manager wants to investigate if the large proportions of the outliers based on `annual_inc` are `Charged Off`. \n",
    "\n",
    "First get the 25th and 75th percentile, then filter for these outliers (without filtering for `Charged Off`, i.e entire dataset) based on the interquartile range. \n",
    "\n",
    "Extract these outliers and filter them for the `loan_status` of `Charged Off` and get the proportion of these outliers with and without `Charged Off`.\n",
    "\n",
    "**Expected Output**:\n",
    "\n",
    "    0.08832807570977919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional - Analysis Comments (No marks but possibly insightful)\n",
    "\n",
    "Add any additional comments/insights about this problem sets and our teaching team could reply to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Checkpoint</b>: When you have completed, upload your progress to eLearn. eLearn only accepts the latest notebooks so if you have an existing notebook, your latest upload will <b>override</b> it.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
