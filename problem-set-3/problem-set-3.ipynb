{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i2.wp.com/hackwagon.com/wp-content/uploads/2017/02/Logo-Web-Export.png?ssl=1\" width=200/>\n",
    "\n",
    "<h1>Hackwagon Academy DS102 - Problem Set 3</h1>\n",
    "<hr>\n",
    "\n",
    "This Problem Set consists of 20 questions, with each correct answer to be awarded 1 mark, totalling up to 20 marks.\n",
    "\n",
    "If you have any questions to the Problem Set, feel free to send a message to your TAs or Instructors in the Telegram chat. You are encouraged to also discuss the problem sets within your own groups.\n",
    "\n",
    "Attempt but minor syntax errors are awarded half the mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before you start, please perform the following 2 steps:\n",
    "#1. Rename the file to FirstName_LastName Hackwagon Academy DS102 - Problem Set 3 e.g. John_Doe Hackwagon Academy DS102 - Problem Set 1\n",
    "\n",
    "#2. Fill in your details here:\n",
    "#Name                    : _______________________\n",
    "\n",
    "#Start of Course Class(Edit accordingly): __7 Jul 2018 3.15pm____\n",
    "\n",
    "# FOR TA/INSTRUCTOR \n",
    "# Total Marks:  / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Credits \n",
    "\n",
    "This problem set is inspired by the [Lending Club Loan Data](https://www.kaggle.com/wendykan/lending-club-loan-data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://d1ic4altzx8ueg.cloudfront.net/niche-builder/5cb94cef96518.png\" width=300>\n",
    "\n",
    "## Context \n",
    "\n",
    "LendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. \n",
    "\n",
    "Your first project is to help LendingClub prepare a prediction model to help them detect loan defaulters. Having already conducted the sufficient exploratory data analysis, your project manager, Silver, wants you to to prepare several machine learning models. Using the dataset which you have preprocessed, `loans_transformed-200k.csv`, you will have to create both <b>supervised and unsupervised machine learning models</b>. Additionally, the `all_loan_desc.csv` dataset prepared for you to prepare a model on the loans descriptions. \n",
    "\n",
    "There are a total of 4 parts to this problem set:\n",
    "\n",
    "1. Naive Bayes Classifier - 8 marks\n",
    "2. K-Means Clustering - 7 marks\n",
    "3. Decision Tree Classifier - 3 marks\n",
    "4. Performance Measures - 2 marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier - 8 marks\n",
    "\n",
    "Another team has prepared for you all of the descriptions within the loans dataset. This dataset has filtered for you rows with descriptions and the target variable the loan status. Your task is to clean it further and use <b>Naive Bayes Classification</b> technique to develop a model for detecting loan defaulters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Loans Decription File \n",
    "\n",
    "Open the file `all_loan_desc.csv` and store it as `all_desc_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Integer Encoding\n",
    "\n",
    "With the target variable `loan_status`, create a new column called `target`, where if the value contains the word `Charged Off`, `Status:Charged Off` or `Default`, it will be `1`; else it will be `0`. Afterwhich, reduce the dataframe to just the `desc` and `target` columns. \n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/ztyxJh0.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARK AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Simple Cleaning\n",
    "\n",
    "To ensure that your model is efficient, conduct simple cleaning on each description where the descriptions:\n",
    "\n",
    "1. Only contains alphanumeric characters (<i>hint: use regular expression</i>)\n",
    "2. Entirely lowercase\n",
    "3. Without trailing or leading spaces \n",
    "4. Not empty strings (<i>hint: use filter</i>)\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/pbLsgSa.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARK AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Tokenize and Stem Words\n",
    "\n",
    "For simplicity and lower processing time, you decided to use `PorterStemmer` to stem each word. As such, you would need to reduce each description to their root form. \n",
    "\n",
    "Steps: \n",
    "\n",
    "1. With the `nltk` library, use `word_tokenize` to tokenize each description (a list of words)\n",
    "2. Use the `PorterStemmer` to stem each word (using a for-loop). \n",
    "3. Join up the stemmed words as a string.\n",
    "\n",
    "All steps above must be done <b>within the same function.</b> Your function should return a string.\n",
    "\n",
    "Using the `apply()` method, create a new column called `desc_stem` to the `all_desc_df`. \n",
    "\n",
    "<b>Note: This part might take awhile to run (an average of 3 minutes).</b>\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/XXDqd3i.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARK AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Stop Words Removal\n",
    "\n",
    "To keep only relevant words, you will remove all stopwords from each description by using the `stopwords` corpus to remove them. \n",
    "\n",
    "Steps: \n",
    "\n",
    "1. Create the list of stopwords in `english`\n",
    "2. Tokenize the each description\n",
    "3. Check for stopwords \n",
    "4. Join up non stopwords as a string\n",
    "\n",
    "All steps, except step 1, must be done <b>within the same function.</b> Your function should return a string.\n",
    "\n",
    "Using the `apply()` method, create a new column called `desc_no_stopwords` to the `all_desc_df`. \n",
    "\n",
    "<b>Note: This part might take awhile to run (an average of 2 minutes).</b>\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/1fED4Uu.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Train Test Split\n",
    "\n",
    "Split your data up into training and testing sets using `sklearn.model_selection` with `train_test_split`, into 4 different variables, `x_train`, `x_test`, `y_train` and `y_test`, where: \n",
    "\n",
    "- <b>first</b> argument should be the `desc_cleaned` column but as a <b>DataFrame (2 square brackets)</b>\n",
    "- <b>second</b> argument should <b>only</b> be the `target` column\n",
    "- `random_state` is 0\n",
    "- `test_size` is 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Vectorizer\n",
    "\n",
    "As you would be using the Naive Bayes Classifier, you would need to transform your description into a matrix of 1s and 0s. Use the `CountVectorizer` to transform your `desc_cleaned` into a matrix, called `desc_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Multinomial Naive Bayes Classifier \n",
    "\n",
    "Create a new `MultinomialNB` classifer and name it as `desc_classifier`, then `.fit()` the vectorized matrix, `desc_matrix` and `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Confusion Matrix\n",
    "\n",
    "Plot the confusion matrix for the Naive Bayes Classifier by:\n",
    "\n",
    "1. Vectorizing (transform) the `x_test` of `desc_cleaned` \n",
    "2. Using `.predict` on the vectorized set from the to get the test results\n",
    "3. Use `sns.heatmap` to create confusion matrix\n",
    "4. Set `.ylim()` to (2,0)\n",
    "5. Set `.xlim()` to (0,2)\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/InjikTM.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering - 7 marks\n",
    "\n",
    "To discover more insights about the dataset, you decided to ran the K-means clustering algorithm to discover the different clusters that could form. \n",
    "\n",
    "### Open Loans Data (Non-Description) File\n",
    "\n",
    "Open the `loans_transformed-200k.csv` as `all_loans_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. Integer Encoding\n",
    "\n",
    "Just as the above Integer Encoding question, create a new column called `target_int` where `Non Default` is `0` and `Default` is `1`. \n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/D0VcNAs.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. Reduce to Numerical Data\n",
    "\n",
    "For K-means algorithm to work properly, your dataframe should only contain numeric datasets. Also, you decide to <b>exclude</b> (drop) the `int_round` and `income_tax` columns are similar to the other columns too. Store this dataframe as `loans_numeric_df`. \n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/80Ccldn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11. Select Optimal K - Elbow Plot\n",
    "\n",
    "Plot the elbow plot by doing multiple iterations of the k-means algorithm, between a value of <b>2 to 15 (inclusive)</b>. Select a K that you think is appropriate to carry on in the next step. \n",
    "\n",
    "<b>Note: This will take about 2 minutes to compute finish all the Ks</b>\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/VQfZN86.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## PLOT MARK: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12. K-Means Clustering with Optimal K - 2 Marks\n",
    "\n",
    "Choose an <b>appropriate K</b> based on the chart above, then apply the k-means algorithm only once and store the model as `loans_kmeans`.\n",
    "\n",
    "Make sure `random_state` is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## KMEANS MARK: /1\n",
    "## SELECTING AN APPROPRIATE K - MARK: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13. Set Labels\n",
    "\n",
    "All loans are now tagged with a particular cluster or label. Using the `.labels_` attribute, create a new column called `label` to `all_loans_df`. \n",
    "\n",
    "**Expected Output:** (for k = 8) \n",
    "\n",
    "<img src=\"https://i.imgur.com/uKpialC.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14. Clustering Analysis\n",
    "\n",
    "Now that you've labelled each loans, you want know the <b>proportion of default loans</b> within each cluster\n",
    "\n",
    "**Expected Output:** (for k = 8) \n",
    "\n",
    "    label  target     \n",
    "    0      Default        0.133062\n",
    "           Non Default    0.866938\n",
    "    1      Non Default    1.000000\n",
    "    2      Default        0.090717\n",
    "           Non Default    0.909283\n",
    "    3      Default        0.055154\n",
    "           Non Default    0.944846\n",
    "    4      Default        0.090909\n",
    "           Non Default    0.909091\n",
    "    5      Default        0.078544\n",
    "           Non Default    0.921456\n",
    "    6      Default        0.062500\n",
    "           Non Default    0.937500\n",
    "    7      Default        0.113032\n",
    "           Non Default    0.886968\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier - 3 marks\n",
    "\n",
    "### Q15. Train Test Split\n",
    "\n",
    "Similar to how you did `train_test_split` on the Decision Tree Classifier, conduct `train_test_split` on the `loans_numeric_df`, into 4 different variables, `x_train`, `x_test`, `y_train` and `y_test`, where: \n",
    "\n",
    "- <b>first</b> argument should be all columns but <b>without</b> the `target_int` column as a <b>DataFrame</b>\n",
    "- <b>second</b> argument should <b>only</b> be the `target_int` column\n",
    "- `random_state` is 0\n",
    "- `test_size` is 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16. Fit DecisionTree\n",
    "\n",
    "Using the `DecisionTreeClassifier`, create a new Decision Tree by using `.fit()` with the `x_train` and `y_train` variables. Name this classifier as `loans_clf`. \n",
    "\n",
    "<b>Note: `random_state` should be `0`.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "loans_clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "loans_clf = loans_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17. Confusion Matrix\n",
    "\n",
    "Plot the confusion matrix for the decision tree classifier by:\n",
    "\n",
    "1. Using `.predict` on the `x_test` to get the test results\n",
    "2. Use `sns.heatmap` to create confusion matrix\n",
    "3. Set `.ylim()` to (2,0)\n",
    "4. Set `.xlim()` to (0,2)\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "<img src=\"https://i.imgur.com/JCRqzHp.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures - 2 marks\n",
    "\n",
    "### Q18. Accuracy & Precision\n",
    "\n",
    "Based on the above confusion matrices, calculate, <b>with workings</b>, the <b>Accuracy and Precision</b> for the:\n",
    "\n",
    "1. Naive Bayes Classifier\n",
    "2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAIVE BAYES CLASSIFIER \n",
    "# Accuracy = \n",
    "# Precision = \n",
    "\n",
    "# DECISION TREE\n",
    "# Accuracy = \n",
    "# Precision = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q19. Model Assessment\n",
    "\n",
    "After assessing the accuracy and precision scores, do you think that the models above are reliable in detecting default loans? Explain your answer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TA/INSTRUCTOR ONLY\n",
    "## MARKS AWARDED: /1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Checkpoint</b>: When you have completed, upload your progress to eLearn. eLearn only accepts the latest notebooks so if you have an existing notebook, your latest upload will <b>override</b> it.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
